{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Convolutional Neural Networks using Tensorflow\n",
    "\n",
    "These are my notes for making a basic CNN using the mnist digit recognizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the data, which has already been preprocessed, from MNIST. Lets also import tensorflow. Our dataset will be 28 pixel by 28 pixel black and white images of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x10880de48>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x10880df60>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x118016550>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters. Lets use a small learning rate of 0.00001, 10 epochs, batch size of 128, validation set size of 256, and 10 classes (one for each digit). For convolutional layers, lets use a convolutional filter size of 5x5, convolutional stride of 1, and 'same' padding. Let use max pooling with a 2x2 pooling size, a pooling stride of 2.  Finally, lets use a dropout probability of 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001 \n",
    "epochs = 10 # Number of times you pass through the entire data sample.\n",
    "batch_size = 128 # Number of samples propagated through the network at a time. Requires less memory than doing the whole network at the same time, and also trains much faster.\n",
    "validation_set_size = 256\n",
    "num_classes = 10  # (0-9 digits)\n",
    "\n",
    "conv_filter_size = 5 # Use a 4x4 convolutional filter.\n",
    "conv_filter_stride = 1\n",
    "padding = 'SAME'\n",
    "\n",
    "pooling_size = 2 # Take the max value of a 2x2 matrix.\n",
    "pooling_stride = 2\n",
    "\n",
    "keep_prob_value = 0.75  # Probability of keeping a unit during dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets design our CNN as follows: input layer, convolutional layer 1, convolutional layer 2, regular layer 1, and output layer. Lets use the relu nonlinear activation function for convolutional layer 1, convolutional layer 2, and regular layer 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN design initialized.\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([conv_filter_size, conv_filter_size, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([conv_filter_size, conv_filter_size, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))}\n",
    "\n",
    "\n",
    "def conv2d(x, weight, bias, conv_filter_stride, padding):\n",
    "    conv = tf.nn.conv2d(x, weight, [1, conv_filter_stride, conv_filter_stride, 1], padding)\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    return tf.nn.relu(conv)\n",
    "\n",
    "def maxpool2d(x, pooling_size, pooling_stride, padding):\n",
    "    return tf.nn.max_pool(x, [1, pooling_size, pooling_size, 1], [1, pooling_stride, pooling_stride, 1], padding)\n",
    "\n",
    "def conv_net(x, weights, biases, keep_prob):\n",
    "    # Convolutional layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], conv_filter_stride, padding)\n",
    "    conv1 = maxpool2d(conv1, pooling_size, pooling_stride, padding)\n",
    "\n",
    "    # Convolutional layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], conv_filter_stride, padding)\n",
    "    conv2 = maxpool2d(conv2, pooling_size, pooling_stride, padding)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "print(\"CNN design initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create some of the things we need to run our neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the neural net! Hopefully it doesn't suck too much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 - Loss: 67377.7266 Validation Accuracy: 0.082031\n",
      "Epoch  1, Batch   2 - Loss: 60716.5820 Validation Accuracy: 0.097656\n",
      "Epoch  1, Batch   3 - Loss: 49919.8125 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch   4 - Loss: 57885.5273 Validation Accuracy: 0.140625\n",
      "Epoch  1, Batch   5 - Loss: 54149.2031 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch   6 - Loss: 44317.6914 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch   7 - Loss: 41870.4922 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch   8 - Loss: 45318.2031 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch   9 - Loss: 42233.7148 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  10 - Loss: 46460.7656 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch  11 - Loss: 41880.0352 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch  12 - Loss: 43589.4453 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  13 - Loss: 44426.3359 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  14 - Loss: 38501.7227 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  15 - Loss: 37110.8594 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  16 - Loss: 42884.5469 Validation Accuracy: 0.214844\n",
      "Epoch  1, Batch  17 - Loss: 37650.6484 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  18 - Loss: 34386.0312 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  19 - Loss: 37178.6172 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch  20 - Loss: 37144.8281 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  21 - Loss: 34376.8438 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  22 - Loss: 37608.4062 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  23 - Loss: 33092.1094 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  24 - Loss: 30935.6211 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  25 - Loss: 29064.3184 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  26 - Loss: 29972.8359 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  27 - Loss: 29272.1133 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  28 - Loss: 35311.1445 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  29 - Loss: 29556.4688 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  30 - Loss: 31803.1562 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  31 - Loss: 28993.5977 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  32 - Loss: 26729.2578 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  33 - Loss: 28437.1797 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  34 - Loss: 26887.1914 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  35 - Loss: 27949.4004 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  36 - Loss: 24746.6113 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  37 - Loss: 27300.7090 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  38 - Loss: 26423.4238 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  39 - Loss: 26294.7578 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  40 - Loss: 23676.8398 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  41 - Loss: 21631.4102 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  42 - Loss: 24426.2949 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  43 - Loss: 25141.4883 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  44 - Loss: 24504.7500 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  45 - Loss: 21966.9668 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  46 - Loss: 21333.7383 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  47 - Loss: 24351.6875 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  48 - Loss: 20951.1719 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  49 - Loss: 21092.1211 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  50 - Loss: 22269.4727 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  51 - Loss: 19707.8047 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  52 - Loss: 21144.2520 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  53 - Loss: 20953.2617 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  54 - Loss: 20385.7695 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  55 - Loss: 20510.2695 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  56 - Loss: 20802.5645 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  57 - Loss: 18429.1602 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  58 - Loss: 19628.6719 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  59 - Loss: 19471.1836 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  60 - Loss: 18461.0234 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  61 - Loss: 23881.5195 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  62 - Loss: 16654.5000 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  63 - Loss: 18227.9043 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  64 - Loss: 16691.5117 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  65 - Loss: 16648.9590 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  66 - Loss: 18345.6602 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  67 - Loss: 18201.7188 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  68 - Loss: 18819.5586 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  69 - Loss: 17420.8359 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  70 - Loss: 18428.6641 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  71 - Loss: 16752.6562 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  72 - Loss: 17775.7559 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  73 - Loss: 14463.0586 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  74 - Loss: 18636.5430 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  75 - Loss: 15671.0977 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  76 - Loss: 17400.9648 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  77 - Loss: 18155.6035 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  78 - Loss: 16439.7031 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  79 - Loss: 18574.6055 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  80 - Loss: 12981.8477 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  81 - Loss: 14811.5215 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  82 - Loss: 15084.3457 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  83 - Loss: 16075.7861 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  84 - Loss: 14809.8359 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  85 - Loss: 13187.2295 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  86 - Loss: 12789.8564 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  87 - Loss: 14175.1045 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  88 - Loss: 14243.9756 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  89 - Loss: 16330.5811 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch  90 - Loss: 12903.8906 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch  91 - Loss: 14505.5254 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  92 - Loss: 13240.1172 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  93 - Loss: 13094.6348 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch  94 - Loss: 14154.7207 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch  95 - Loss: 14714.9199 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  96 - Loss: 12655.6895 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  97 - Loss: 12506.5244 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch  98 - Loss: 14452.1543 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch  99 - Loss: 12881.7500 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 100 - Loss: 13665.6211 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 101 - Loss: 13822.9365 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 102 - Loss: 12855.0762 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 103 - Loss: 14228.9307 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 104 - Loss: 13162.4824 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 105 - Loss: 14915.2197 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 106 - Loss: 13468.1738 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 107 - Loss: 12531.1084 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 108 - Loss: 11295.6357 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 109 - Loss: 14017.6865 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 110 - Loss: 11506.5117 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 111 - Loss: 13192.3125 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 112 - Loss: 12028.2373 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 113 - Loss: 12676.2568 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 114 - Loss: 12432.8564 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 115 - Loss: 10802.4922 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 116 - Loss: 11888.5967 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 117 - Loss: 12696.1250 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 118 - Loss: 11607.3496 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 119 - Loss: 13795.3066 Validation Accuracy: 0.621094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 120 - Loss: 11945.5176 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 121 - Loss: 11110.9189 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 122 - Loss: 10286.7734 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 123 - Loss: 11292.5547 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 124 - Loss: 11744.3350 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 125 - Loss: 12417.9824 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 126 - Loss: 10278.1016 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 127 - Loss:  9878.3926 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 128 - Loss: 13725.9863 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 129 - Loss:  8910.6191 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 130 - Loss: 11989.2188 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 131 - Loss: 10144.7129 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 132 - Loss:  9692.2920 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 133 - Loss: 11137.6289 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 134 - Loss: 12763.3564 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 135 - Loss: 13066.4102 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 136 - Loss:  9907.9990 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 137 - Loss: 10004.7500 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 138 - Loss:  8714.6270 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 139 - Loss: 12408.2168 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 140 - Loss: 13617.3555 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 141 - Loss:  9266.7344 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 142 - Loss: 11272.5059 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 143 - Loss: 10242.8887 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 144 - Loss:  8467.7598 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 145 - Loss:  7691.0957 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 146 - Loss:  8182.4502 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 147 - Loss: 10648.1621 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 148 - Loss:  8044.3315 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 149 - Loss: 10100.9893 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 150 - Loss: 11116.3633 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 151 - Loss: 10282.9102 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 152 - Loss:  9250.8887 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 153 - Loss:  9067.4785 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 154 - Loss: 10094.7041 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 155 - Loss: 10064.8281 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 156 - Loss:  8968.6475 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 157 - Loss:  8894.5342 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 158 - Loss: 10163.8125 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 159 - Loss:  8848.7305 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 160 - Loss:  9216.9863 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 161 - Loss:  9962.8477 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 162 - Loss:  7677.7183 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 163 - Loss:  9985.6836 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 164 - Loss: 10163.2568 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 165 - Loss:  8858.1045 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 166 - Loss:  8680.5215 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 167 - Loss:  8648.6719 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 168 - Loss:  9139.1582 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 169 - Loss:  7064.4756 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 170 - Loss:  8218.6641 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 171 - Loss: 10902.9316 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 172 - Loss:  9724.9922 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 173 - Loss:  8583.1113 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 174 - Loss:  8905.6836 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 175 - Loss:  8823.4609 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 176 - Loss:  7847.1758 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 177 - Loss:  8429.9893 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 178 - Loss:  7865.1387 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 179 - Loss:  8825.8320 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 180 - Loss:  7746.8545 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 181 - Loss:  7448.3740 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 182 - Loss:  6149.5483 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 183 - Loss:  7416.1299 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 184 - Loss:  8718.0947 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 185 - Loss:  7430.6963 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 186 - Loss:  8125.1401 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 187 - Loss:  8378.0918 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 188 - Loss:  7400.6489 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 189 - Loss:  7945.3364 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 190 - Loss:  6703.0200 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 191 - Loss:  7230.5039 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 192 - Loss:  8172.8325 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 193 - Loss:  7040.4375 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 194 - Loss:  8139.5371 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 195 - Loss:  8151.2671 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 196 - Loss:  5982.3633 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 197 - Loss:  6999.6694 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 198 - Loss:  6591.6196 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 199 - Loss:  5944.8486 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 200 - Loss:  8173.6162 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 201 - Loss:  6332.7568 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 202 - Loss:  7520.4414 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 203 - Loss:  6844.5664 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 204 - Loss:  7579.1895 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 205 - Loss:  7936.6626 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 206 - Loss:  6224.5078 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 207 - Loss:  7283.7969 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 208 - Loss:  5344.1250 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 209 - Loss:  8074.8496 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 210 - Loss:  7119.9268 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 211 - Loss:  6660.3154 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 212 - Loss:  7346.8486 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 213 - Loss:  7801.8418 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 214 - Loss:  7171.8467 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 215 - Loss:  5681.2192 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 216 - Loss:  6506.3301 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 217 - Loss:  6795.7158 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 218 - Loss:  7357.5942 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 219 - Loss:  6066.8945 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 220 - Loss:  7592.0229 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 221 - Loss:  6635.4858 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 222 - Loss:  6102.1514 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 223 - Loss:  6276.5205 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 224 - Loss:  7517.4326 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 225 - Loss:  7462.5928 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 226 - Loss:  8328.5615 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 227 - Loss:  6654.5142 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 228 - Loss:  5737.7139 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 229 - Loss:  7348.5767 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 230 - Loss:  6416.2554 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 231 - Loss:  8350.4473 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 232 - Loss:  7010.9458 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 233 - Loss:  5211.8799 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 234 - Loss:  7076.9736 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 235 - Loss:  5824.0586 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 236 - Loss:  5758.0347 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 237 - Loss:  6561.6050 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 238 - Loss:  5421.8535 Validation Accuracy: 0.753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 239 - Loss:  8440.2998 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 240 - Loss:  5569.3765 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 241 - Loss:  6429.1523 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 242 - Loss:  6945.4795 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 243 - Loss:  6012.9351 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 244 - Loss:  6369.4580 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 245 - Loss:  4822.4121 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 246 - Loss:  7189.6104 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 247 - Loss:  6521.1113 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 248 - Loss:  5958.1455 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 249 - Loss:  6475.0186 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 250 - Loss:  6277.2993 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 251 - Loss:  6325.1221 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 252 - Loss:  6196.2031 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 253 - Loss:  5256.9595 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 254 - Loss:  5490.5459 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 255 - Loss:  7076.7803 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 256 - Loss:  6650.7773 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 257 - Loss:  7160.7075 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 258 - Loss:  7862.4463 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 259 - Loss:  4236.1230 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 260 - Loss:  6685.0117 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 261 - Loss:  5649.7412 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 262 - Loss:  5694.4922 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 263 - Loss:  5639.4316 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 264 - Loss:  5032.9131 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 265 - Loss:  5486.3877 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 266 - Loss:  5981.0078 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 267 - Loss:  5314.9307 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 268 - Loss:  5860.1387 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 269 - Loss:  5915.3760 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 270 - Loss:  6165.9443 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 271 - Loss:  6069.5894 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 272 - Loss:  4530.2900 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 273 - Loss:  5849.9780 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 274 - Loss:  5966.9019 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 275 - Loss:  5750.5454 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 276 - Loss:  4557.7485 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 277 - Loss:  6282.2031 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 278 - Loss:  5282.3232 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 279 - Loss:  5702.2778 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 280 - Loss:  6955.2793 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 281 - Loss:  4602.7734 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 282 - Loss:  4885.0723 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 283 - Loss:  7408.9019 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 284 - Loss:  5937.2832 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 285 - Loss:  5765.0850 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 286 - Loss:  4735.7144 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 287 - Loss:  5752.3335 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 288 - Loss:  4382.2383 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 289 - Loss:  6966.5898 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 290 - Loss:  5616.3599 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 291 - Loss:  5116.1421 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 292 - Loss:  5817.6826 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 293 - Loss:  6226.7822 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 294 - Loss:  5376.9126 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 295 - Loss:  5521.1753 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 296 - Loss:  4995.6733 Validation Accuracy: 0.800781\n",
      "Epoch  1, Batch 297 - Loss:  4495.3154 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 298 - Loss:  5746.5630 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 299 - Loss:  5714.6685 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 300 - Loss:  4487.2959 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 301 - Loss:  5641.3457 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 302 - Loss:  5185.6187 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 303 - Loss:  6366.9160 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 304 - Loss:  4612.9067 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 305 - Loss:  5320.2500 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 306 - Loss:  5483.5762 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 307 - Loss:  5284.5093 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 308 - Loss:  5112.4507 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 309 - Loss:  4565.5283 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 310 - Loss:  5487.0498 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 311 - Loss:  4973.7847 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 312 - Loss:  5917.7568 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 313 - Loss:  4828.6650 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 314 - Loss:  4867.9668 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 315 - Loss:  5331.2158 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 316 - Loss:  6009.5254 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 317 - Loss:  4800.3628 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 318 - Loss:  4973.9429 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 319 - Loss:  4799.7920 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 320 - Loss:  5486.9019 Validation Accuracy: 0.796875\n",
      "Epoch  1, Batch 321 - Loss:  5609.1758 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 322 - Loss:  5163.5576 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 323 - Loss:  5692.4082 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 324 - Loss:  5657.7817 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 325 - Loss:  5857.9248 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 326 - Loss:  5214.2354 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 327 - Loss:  4784.5498 Validation Accuracy: 0.812500\n",
      "Epoch  1, Batch 328 - Loss:  5839.1279 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 329 - Loss:  4223.4014 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 330 - Loss:  5617.0845 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 331 - Loss:  5033.2017 Validation Accuracy: 0.812500\n",
      "Epoch  1, Batch 332 - Loss:  4589.0752 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 333 - Loss:  5372.6367 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 334 - Loss:  4468.3208 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 335 - Loss:  5848.4004 Validation Accuracy: 0.812500\n",
      "Epoch  1, Batch 336 - Loss:  3867.5913 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 337 - Loss:  5281.5361 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 338 - Loss:  4290.1851 Validation Accuracy: 0.812500\n",
      "Epoch  1, Batch 339 - Loss:  4140.6851 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 340 - Loss:  4671.9233 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 341 - Loss:  5341.8262 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 342 - Loss:  4354.4028 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 343 - Loss:  4588.9502 Validation Accuracy: 0.808594\n",
      "Epoch  1, Batch 344 - Loss:  4398.4707 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 345 - Loss:  4364.3516 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 346 - Loss:  6026.8931 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 347 - Loss:  3801.9436 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 348 - Loss:  3921.2258 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 349 - Loss:  4535.6782 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 350 - Loss:  3962.3276 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 351 - Loss:  4168.0933 Validation Accuracy: 0.812500\n",
      "Epoch  1, Batch 352 - Loss:  5378.1709 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 353 - Loss:  4493.8159 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 354 - Loss:  4781.8208 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 355 - Loss:  4788.3115 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 356 - Loss:  4185.9092 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 357 - Loss:  5148.0474 Validation Accuracy: 0.820312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 358 - Loss:  4429.1440 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 359 - Loss:  4085.9180 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 360 - Loss:  5414.0474 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 361 - Loss:  4330.7407 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 362 - Loss:  5353.8198 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 363 - Loss:  4751.0664 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 364 - Loss:  4257.9561 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 365 - Loss:  5488.0029 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 366 - Loss:  4300.6260 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 367 - Loss:  6096.9922 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 368 - Loss:  3128.4941 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 369 - Loss:  4947.4893 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 370 - Loss:  4264.2651 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 371 - Loss:  3487.5215 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 372 - Loss:  5137.5518 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 373 - Loss:  4109.9297 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 374 - Loss:  4277.2422 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 375 - Loss:  4693.2939 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 376 - Loss:  4850.3481 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 377 - Loss:  4947.9824 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 378 - Loss:  4417.2056 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 379 - Loss:  4403.6118 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 380 - Loss:  4438.2012 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 381 - Loss:  3858.5886 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 382 - Loss:  3151.3772 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 383 - Loss:  3983.3057 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 384 - Loss:  4919.5918 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 385 - Loss:  3750.8311 Validation Accuracy: 0.843750\n",
      "Epoch  1, Batch 386 - Loss:  4717.2319 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 387 - Loss:  5868.3530 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 388 - Loss:  4774.4326 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 389 - Loss:  4390.9512 Validation Accuracy: 0.843750\n",
      "Epoch  1, Batch 390 - Loss:  4430.6855 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 391 - Loss:  4693.8467 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 392 - Loss:  4807.5947 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 393 - Loss:  4036.4976 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 394 - Loss:  3495.6895 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 395 - Loss:  3175.8750 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 396 - Loss:  5267.1479 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 397 - Loss:  4292.2373 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 398 - Loss:  5372.9531 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 399 - Loss:  3967.0120 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 400 - Loss:  3477.9937 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 401 - Loss:  4669.2549 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 402 - Loss:  5001.6885 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 403 - Loss:  4025.4451 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 404 - Loss:  4401.4883 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 405 - Loss:  3400.9487 Validation Accuracy: 0.824219\n",
      "Epoch  1, Batch 406 - Loss:  5676.0010 Validation Accuracy: 0.820312\n",
      "Epoch  1, Batch 407 - Loss:  3808.4661 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 408 - Loss:  3509.8835 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 409 - Loss:  3869.2014 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 410 - Loss:  3553.2231 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 411 - Loss:  4614.4131 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 412 - Loss:  4173.2217 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 413 - Loss:  4357.0913 Validation Accuracy: 0.828125\n",
      "Epoch  1, Batch 414 - Loss:  3126.2354 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 415 - Loss:  5322.4170 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 416 - Loss:  3614.2397 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 417 - Loss:  3877.1362 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 418 - Loss:  3434.5574 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 419 - Loss:  4380.6104 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 420 - Loss:  3981.4492 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 421 - Loss:  4061.4795 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 422 - Loss:  4603.1699 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 423 - Loss:  4998.1099 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 424 - Loss:  3793.8489 Validation Accuracy: 0.835938\n",
      "Epoch  1, Batch 425 - Loss:  3233.6382 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 426 - Loss:  4773.5898 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 427 - Loss:  4525.5571 Validation Accuracy: 0.832031\n",
      "Epoch  1, Batch 428 - Loss:  3477.6587 Validation Accuracy: 0.839844\n",
      "Epoch  1, Batch 429 - Loss:  4815.0811 Validation Accuracy: 0.839844\n",
      "Epoch  2, Batch   1 - Loss:  4566.8613 Validation Accuracy: 0.839844\n",
      "Epoch  2, Batch   2 - Loss:  3428.7615 Validation Accuracy: 0.835938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9d1357040a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.75})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.75})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:validation_set_size],\n",
    "                y: mnist.validation.labels[:validation_set_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
